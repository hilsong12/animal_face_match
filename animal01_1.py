import os
import glob
from icrawler.builtin import BingImageCrawler, GoogleImageCrawler
from PIL import Image

# ============================================================
# 0) ì„¤ì •
# ============================================================
SAVE_DIR = './animal_dataset'
TARGET_COUNT_PER_SITE = 200       # ì‚¬ì´íŠ¸ë‹¹ 200ì¥ â†’ ì´ 400ì¥ ì˜ˆìƒ
FINAL_TARGET_COUNT = 800          # ìµœì¢… ëª©í‘œì¹˜

categories = [
    "Bear",
    "Cat",
    "Cattle",
    "Chicken",
    "Deer",
    "Dog",
    "Duck",
    "Fox",
    "Hamster",
    "Horse",
    "Lion",
    "Monkey",
    "Pig",
    "Rabbit",
    "Sheep",
    "Turtle"
]

extra_keywords = [
    "cute", "wildlife", "hd", "4k", "close up", "real photo"
]

# ============================================================
# 1) í´ë” ìƒì„±
# ============================================================
os.makedirs(SAVE_DIR, exist_ok=True)
for c in categories:
    os.makedirs(os.path.join(SAVE_DIR, c), exist_ok=True)


# ============================================================
# 2) JPG ë³€í™˜ í•¨ìˆ˜
# ============================================================
def convert_to_jpg(folder):
    files = glob.glob(os.path.join(folder, '*'))
    converted = 0

    for f in files:
        try:
            img = Image.open(f).convert('RGB')
            new_name = os.path.splitext(f)[0] + ".jpg"
            img.save(new_name, 'JPEG')

            if f != new_name:
                os.remove(f)
            converted += 1

        except Exception:
            if os.path.exists(f):
                os.remove(f)

    print(f" â†’ JPG ë³€í™˜ ì™„ë£Œ: {converted}ì¥")


# ============================================================
# 3) Bing + Google ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
# ============================================================
def download_from_sources(keyword, folder):

    # Bing
    print("  - Bing í¬ë¡¤ë§...")
    bing = BingImageCrawler(storage={'root_dir': folder})
    bing.crawl(
        keyword=keyword,
        max_num=TARGET_COUNT_PER_SITE,
        min_size=(50, 50)
    )

    # Google
    print("  - Google í¬ë¡¤ë§...")
    google = GoogleImageCrawler(storage={'root_dir': folder})
    google.crawl(
        keyword=keyword,
        max_num=TARGET_COUNT_PER_SITE,
        min_size=(50, 50)
    )


# ============================================================
# 4) ë³¸ê²© ë‹¤ìš´ë¡œë“œ
# ============================================================
for c in categories:

    print(f"\n======================================")
    print(f"   ğŸ¦Š {c} ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
    print("======================================")

    folder = os.path.join(SAVE_DIR, c)

    # ê²€ìƒ‰ì–´ ë‹¤ì–‘í™” ë°˜ë³µ
    for k in extra_keywords:
        full_keyword = f"{c} {k} animal"
        print(f" ê²€ìƒ‰ì–´: {full_keyword}")
        download_from_sources(full_keyword, folder)

    # JPG ë³€í™˜
    convert_to_jpg(folder)

    # ê°œìˆ˜ ì²´í¬
    count = len(glob.glob(os.path.join(folder, "*.jpg")))
    print(f"í˜„ì¬ {c} ì´ë¯¸ì§€ ê°œìˆ˜: {count}ì¥\n")

    if count < FINAL_TARGET_COUNT:
        print(f"âš  {c}ëŠ” ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ â†’ ë” ë§ì€ ê²€ìƒ‰ì–´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì‚¬ì´íŠ¸ í•„ìš”")


print("\nğŸ‰ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
